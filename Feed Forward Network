library(R.matlab)

###Creating the Feed forward Network Assuming Theta1 and Theta2 have been trained

data <- readMat("..../mlclass-ex4/ex4data1.mat")
weights_initial <- readMat("...../mlclass-ex4/ex4weights.mat")
weights_initial_Theta1 <- data.frame(weights_initial$Theta1)
weights_initial_Theta2 <- data.frame(weights_initial$Theta2)


data_x <- data.frame(data$X)

###Adding bias unit in the first layer
data_x <- data.frame(cbind(as.vector(rep(1, nrow(data_x))),data_x) )
colnames(data_x)[1] <- c("bias")

data_y <- data.frame(data$y)

nrow(data_x)

sigmoid_function <- function(z)
{
  return(1/(1+exp(-z)))
  
}


###Transformed Xs using Thetas  Weights * T in the second layer
z2 <- as.matrix(data_x) %*% t(as.matrix(weights_initial_Theta1))
##Activation in the second layer
a2 <- sigmoid_function(z2)

##Adding a bias unit to all the training records
z2  <- as.matrix(cbind(as.vector(rep(1, nrow(a2))),a2))
###Transformed Xs using Thetas  Weights * T in the second layer
z3 <- as.matrix(z2) %*% t(as.matrix(weights_initial_Theta2))

###Activation in the third layer
a3 <- sigmoid_function(z3)

results <- data.frame(matrix(0, nrow = nrow(a3), ncol = 1))

for( i in 1:nrow(a3))
{
  results[i,1] <- which.max(a3[i,])
}

final_res <- data.frame(table(data_y == results))

##Accuracy
final_res[2,2]/(final_res[1,2]+final_res[2,2])

Acc = 0.9752
